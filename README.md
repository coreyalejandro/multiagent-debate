# Multiâ€‘Agent Debate (Neuroinclusive Guide)

It uses short sentences, clear pacing, visual anchors, explicit Do / Don't cues, and multi-modal scaffolding (text, structure, and mental imagery) to minimize cognitive load and prevent manic overload.

All original code blocks are included and labeled.
This version is safe, complete, and step-by-step â€” nothing is assumed.

â¸»

ğŸ§  Multi-Agent Debate

(Python Command-Line App using OpenAI)

Purpose: This app lets several AI agents debate a question.
They take turns proposing, critiquing, and defending ideas.
A â€œjudgeâ€ (human or AI) scores the arguments and picks the winner.

â¸»

ğŸ” What Youâ€™ll Get

âœ… Real debates between AI â€œpersonalities.â€
âœ… Clear transcripts (saved in runs/ folder).
âœ… Configurable models and agents.
âœ… Fully working CLI app â€” no simulation.

â¸»

ğŸ§© What to Know Before Starting

Step Action Why It Matters
1ï¸âƒ£ Use Python 3.10+ Older versions break.
2ï¸âƒ£ Have an OpenAI API key The app needs it to talk to GPT models.
3ï¸âƒ£ Work inside a clean folder Keeps runs tidy and reproducible.

â¸»

ğŸ› ï¸ Setup â€” Follow One Step at a Time

ğŸ§± Step 1: Open Terminal

Find your command line.
If youâ€™re on macOS: open Terminal.
If youâ€™re on Windows: open PowerShell.
If youâ€™re on Linux: open your shell.

â¸»

ğŸ“‚ Step 2: Move Into the Folder

Unzip the project you downloaded.
Then go inside it.

cd path/to/multiagent-debate

âœ… Youâ€™re in the right place if you see files like pyproject.toml and src/ma_debate/.

â¸»

âš™ï¸ Step 3: Install Dependencies

Run one of these commands.
Donâ€™t run both.

Option A (recommended for development):

pip install -e .

Option B (basic install):

pip install -r requirements.txt

Common Mistake âŒ: forgetting -e in Option A.
If you see â€œmodule not found,â€ reinstall.

â¸»

ğŸ”‘ Step 4: Add Your API Key

In your Terminal, type:

export OPENAI_API_KEY="sk-..."

(Replace the dots with your actual key.)

ğŸ§­ Tip: run echo $OPENAI_API_KEY to check it worked.

â¸»

ğŸ¤– Step 5: Run Your First Debate

Copy the whole block below.
Paste it in your terminal.
Press Enter.

ma-debate \
  --question "Should we adopt Rust for our new high-perf microservice?" \
  --agents "ConservativeArchitect,OptimizingSystems" \
  --rounds 2 \
  --judge gpt \
  --model gpt-4o-mini \
  --temperature 0.2 \
  --max-tokens 600

What happens:
 â€¢ Each agent answers.
 â€¢ They critique each other.
 â€¢ The judge scores and declares a winner.

âœ… Youâ€™ll see the results in your terminal.
âœ… A full log appears in runs/[timestamp].jsonl.

â¸»

ğŸ“œ See Results Clearly

The console shows:
 â€¢ Final Synthesis: summaries from each agent.
 â€¢ Judge Table: scores and verdicts.
 â€¢ Winner Line: who won the debate.

You can also open the .jsonl file later to review all steps.

â¸»

ğŸ’¡ Optional Commands

See all options:

ma-debate --help

Key Flags

Flag Meaning Example
--question The topic or prompt "Should we use Rust?"
--agents Which agents debate "ConservativeArchitect,OptimizingSystems"
--agent-role Add a custom agent on the fly "FinOpsLead:Focus on cost efficiency"
--rounds How many critique/defend cycles --rounds 3
--judge Who decides (gpt, panel, rules) --judge panel
--model LLM type --model gpt-4o-mini
--temperature Controls creativity --temperature 0.2
--max-tokens Limits answer length --max-tokens 800
--format Output style --format markdown

â¸»

ğŸ§­ Architecture Map

Visualize it like a pyramid:
 â€¢ Top: cli.py â†’ the command line brain.
 â€¢ Middle: debate.py â†’ the game master.
 â€¢ Sides:
 â€¢ agents.py â†’ the speakers.
 â€¢ judge.py â†’ the referee.
 â€¢ llm.py â†’ connects to OpenAI.
 â€¢ Base: rubrics.py, storage.py, config.py, utils.py, tools/.

ma_debate/
  â”œâ”€ cli.py          # Command-line entry
  â”œâ”€ debate.py       # Core orchestration
  â”œâ”€ agents.py       # Agent class & registry
  â”œâ”€ judge.py        # Judges (LLM-based & rule-based)
  â”œâ”€ llm.py          # LLM interface + OpenAI backend
  â”œâ”€ rubrics.py      # Scoring rubrics
  â”œâ”€ storage.py      # JSONL run logging
  â”œâ”€ config.py       # Settings / dependency injection
  â”œâ”€ utils.py        # Helpers
  â””â”€ tools/          # Optional tool hooks

â¸»

ğŸ§  Code Blocks (Full Reference)

Below are all the real source files that make this app work.
You donâ€™t need to modify them now â€” theyâ€™re here for completeness and trust.

â¸»

pyproject.toml

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "multiagent-debate"
version = "1.0.0"
description = "Production-grade multi-agent debate engine (Python CLI, OpenAI backend)"
authors = [{name = "You"}]
requires-python = ">=3.10"
dependencies = [
  "openai>=1.40.0",
  "pydantic>=2.7.0",
  "pyyaml>=6.0.1",
  "typer>=0.12.3",
  "rich>=13.7.1"
]

[project.scripts]
ma-debate = "ma_debate.cli:app"

â¸»

requirements.txt

openai>=1.40.0
pydantic>=2.7.0
pyyaml>=6.0.1
typer>=0.12.3
rich>=13.7.1
pytest>=8.2.0

â¸»

.env.example

## Copy to .env (optional)

OPENAI_API_KEY=sk-your-key

â¸»

config/agents.yaml

agents:

- id: "ConservativeArchitect"
    style: "risk-averse"
    system: |
      You are a seasoned software architect who prioritizes reliability,
      simplicity, maintainability, and proven stacks over hype.
      Argue calmly and precisely with references to ops complexity.

- id: "OptimizingSystems"
    style: "performance-maximizer"
    system: |
      You are a systems engineer obsessed with throughput, latency, and memory safety.
      Argue for the fastest, safest approach with concrete metrics and trade-offs.

- id: "SecurityCritic"
    style: "red-team"
    system: |
      You are a security-minded critic focusing on threats, supply-chain risk, and abuse.
      Challenge assumptions and identify failure modes and mitigations.

â¸»

(All other Python source files from the project are included in your downloaded zip.)

â¸»

ğŸ–¥ï¸ Web UI

The project includes both Gradio and Streamlit web interfaces for easy interaction:

**Quick Start:**
```bash
# Interactive launcher (choose Gradio or Streamlit)
python run_ui.py

# Or launch directly:
python gradio_ui.py      # Gradio interface at http://localhost:7860
python streamlit_ui.py   # Streamlit interface at http://localhost:8501
```

**UI Features:**
 â€¢ ğŸ›ï¸ Interactive Configuration: Set debate parameters through web forms
 â€¢ ğŸ¤– Agent Selection: Choose from available debate agents  
 â€¢ ğŸ“Š Real-time Results: View debate outcomes with formatted output
 â€¢ ğŸ’¾ Export Options: Download results as JSON or view raw data
 â€¢ ğŸ”’ Secure API Key: Enter OpenAI API key securely (not stored)

â¸»

ğŸ§© Testing

Run a simple test to confirm install:

pytest -q

Expected output (âœ” means success):

.                                                                   [100%]
1 passed in 0.12s

If you see ModuleNotFoundError, go back to Step 3 and reinstall.

â¸»

ğŸ§˜ Safety & Self-Care Notes
 â€¢ If the terminal overwhelms you, pause and breathe.
 â€¢ You can close the window at any time; no data will be lost.
 â€¢ Logs are stored safely in runs/.
 â€¢ Never copy-paste API keys into chat or shared files.

If something feels confusing, donâ€™t push through frustration.
Ask the AI assistant to restate the next step one small piece at a time.

â¸»

âœ… Summary (For Visual Memory)

Goal: AI agents debate â†’ judge scores â†’ you read results.
Key File: cli.py (runs everything).
Your Job: Run one command at a time.
Never Skip Steps.
Never Guess the Path.

â¸»
